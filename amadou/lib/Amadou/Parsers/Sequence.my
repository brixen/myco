
Amadou << {
  Parsers << {
    
    Sequence: Base {
      parse: |group| {
        # Scan/replace for pre-combine atoms
        [
          word_punctuator
          symbol_atomizer
          constant_atomizer
        ].each |scanner| {
          group.phrases.each |phrase| {
            phrase.list = scanner.scan_replace(phrase.list)
          }
        }
        
        # Tag phrases where the previous phrase ends with a newline which
        # match a pattern suggesting it is a continuation of the last phrase.
        group.phrases.each_cons(2) |last_phrase, phrase| {
          last_phrase.delim_eq?("\n") && (
            state = left_combine_finder.parse(phrase.list)
            state.end_idx && last_phrase.tagged(:join_to_next)
          )
        }
        
        # Tag phrases which end with a newline and match a pattern suggesting
        # that the next phrase is a continuation of it.
        group.phrases.each_cons(2) |phrase, _| {
          phrase.delim_eq?("\n") && (
            state = right_combine_finder.parse(phrase.list)
            state.end_idx && phrase.tagged(:join_to_next)
          )
        }
        
        output = []
        ongoing_list = []
        
        group.phrases.each |phrase| {
          # Concatenate the phrase items to the ongoing list,
          # joining the newly adjacent space items into a single token.
          ongoing_list.empty? &? (
            ongoing_list = phrase.list.dup
          ) ?? (
            list = phrase.list.dup
            ongoing_list.push((ongoing_list.pop + list.shift).tagged(:space))
            ongoing_list.concat(list)
          )
          
          # If not tagged as join_to_next, parse the ongoing joined phrase.
          phrase.tagged?(:join_to_next) || (
            state = parser.parse(ongoing_list)
            state.end_idx || raise("No known meaning for sequence phrase list: "ongoing_list.inspect"")
            result = state.result[:root]
            result.is_a?(Hash) && (result = [result.delete(:type), result]) # TODO: use atom format everywhere?
            output.push(handlers.__send__(*result))
            
            ongoing_list.clear
          )
        }
        
        ongoing_list.empty? || raise("No known meaning for sequence phrase list: "ongoing_list.inspect"")
        
        AST::Sequence.new(line: group.start.line, array: output.compact)
      }
      
      # Join question marks or exclamation points onto the end of local words.
      const word_punctuator: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          const local_word_pattern: Regexp.new("^([[:lower:]]|_)")
          
          zs:           si([:tagged?, [:space],  true], [:size, [], 0])
          glyph: |text| si([:tagged?, [:glyph], true], [:text, [], text])
          local_word:   si([:tagged?, [:word],  true]
                           [:match?,  [local_word_pattern], true])
          
          [rules]
          
          rule root: symbol[:root]
          
          rule symbol:
            r(local_word[:start] + zs + (glyph("?") / glyph("!"))[:finish])
              { (start + finish).tagged(:word) }
        }
      }
      
      # Detect and convert symbol atoms.
      const symbol_atomizer: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          const local_word_pattern: Regexp.new("^([[:lower:]]|_)")
          
          zs:           si([:tagged?, [:space],  true], [:size, [], 0])
          str:          si([:tagged?, [:string], true])
          glyph: |text| si([:tagged?, [:glyph], true], [:text, [], text])
          local_word:   si([:tagged?, [:word],  true]
                           [:match?,  [local_word_pattern], true])
          
          [rules]
          
          rule root: symbol[:root]
          
          rule symbol:
            r(glyph(":")[:loc] + zs + str[:content])
              { (loc + content.finish)
                  .tagged(:atom).with_data(type: :symbol, content: content) }
          / r(glyph(":")[:loc] + zs + local_word[:content])
              { (loc + content)
                  .tagged(:atom).with_data(type: :symbol, content: content) }
        }
      }
      
      # Detect and convert constant atoms.
      const constant_atomizer: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          const upper_word_pattern: Regexp.new("^[[:upper:]]")
          
          zs:           si([:tagged?, [:space],  true], [:size, [], 0])
          glyph: |text| si([:tagged?, [:glyph], true], [:text, [], text])
          upper_word:   si([:tagged?, [:word],  true]
                           [:match?,  [upper_word_pattern], true])
          
          [rules]
          
          rule root: constant[:root]
          
          cc: glyph(":") +zs+ glyph(":")
          
          rule cc_constant: r(zs+ cc +zs+ upper_word[:t]) { t }
          rule cc_zs:       r(cc[:t] +zs) { t }
          
          rule constant:
            r(cc_zs.-[:top] + upper_word[:tc] + cc_constant.*[:trest])
              { (tc + (trest.last || tc)).tagged(:atom)
                  .with_data(type: :constant, top: !!top, words: [tc]+trest) }
        }
      }
      
      # Match phrases that look like a continuation of the previous phrase.
      const left_combine_finder: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          s:           si([:tagged?, [:space], true])
          anyglyph:    si([:tagged?, [:glyph], true])
          brace_group: si([:tagged?, [:group], true]
                          [:start_eq?, [:"{"], true])
          
          [rules]
          
          # TODO: don't match for unary operators that start a phrase.
          rule root:
            s+ (anyglyph / brace_group) # followed by whatever - we don't care
        }
      }
      
      # Match phrases that look like they continue into the next phrase.
      const right_combine_finder: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          s:        si([:tagged?, [:space], true])
          nonglyph: si([:tagged?, [:glyph], false])
          anyglyph: si([:tagged?, [:glyph], true])
          
          [rules]
          
          rule maybe_nons_then_anys:
            (nonglyph +s).* + (anyglyph +s).+
          
          # TODO: don't match for invoke operators (like .+) that end a phrase.
          rule root:
            s+ maybe_nons_then_anys.+ +esi
        }
      }
      
      const parser: Pegleromyces::Stream::Parser {
        const grammar: Pegleromyces::Grammar {
          const integer_pattern:    Regexp.new("^[0-9]+$")
          const local_word_pattern: Regexp.new("^([[:lower:]]|_)")
          
          s:            si([:tagged?, [:space],  true])
          zs:           si([:tagged?, [:space],  true], [:size, [], 0])
          str:          si([:tagged?, [:string], true])
          glyph: |text| si([:tagged?, [:glyph],  true], [:text, [], text])
          word:  |text| si([:tagged?, [:word],   true], [:text, [], text])
          
          integer_word: si([:tagged?, [:word],  true]
                           [:match?,  [integer_pattern], true])
          local_word:   si([:tagged?, [:word],  true]
                           [:match?,  [local_word_pattern], true])
          paren_group:  si([:tagged?, [:group], true]
                           [:start_eq?, [:"("], true])
          brace_group:  si([:tagged?, [:group], true]
                           [:start_eq?, [:"{"], true])
          brack_group:  si([:tagged?, [:group], true]
                           [:start_eq?, [:"["], true])
          
          mglyph: |mtext| {
            texts = mtext.each_codepoint.map |code| { [code].pack("U*") }
            
            patt = si([:tagged?, [:glyph], true], [:text, [], texts.shift])
            
            texts.each |text| {
              patt = patt + zs +
                si([:tagged?, [:glyph], true], [:text, [], texts.shift])
            }
            
            patt = patt[:mglyph]
            
            r(patt) { mglyph.first + mglyph.last }
          }
          
          [rules]
          rule root: s+ (
              none
            / left_chained_operations
            / expr_atom
          )[:root] +s.-+esi
          
          rule none: r(!!esi) { [:none, captures] }
          
          rule expr_atom:
            left_chained_invocations
          / atom_token
          / string
          / unary_operation
          / paren_expr
          / integer
          / invoke
          
          rule expr_atom_not_chained:
            atom_token
          / string
          / unary_operation
          / paren_expr
          / integer
          / invoke
          
          rule atom_token:
            r(si([:tagged?, [:atom], true])[:atom])
              { atom.data.merge(loc: atom) }
          
          rule integer:
            r(integer_word[:integer])
              { [:integer, captures] }
          
          rule string:
            r(str[:content])
              { [:string, loc: content.start, content: content.content] }
          
          rule paren_expr:
            r(paren_group[:group])
              { [:sequence, group: group] }
          
          ##
          # Unary operators
          
          rule unary_operation:
            r(glyph("!")[:t0] +s+ expr_atom[:n0])
              { [:invoke, loc: t0, receiver: n0, name: t0.sym,
                  arguments: null, block: null] }
          
          ##
          # Two-term operators
          
          left_op_normal: r((
              r((mglyph("**"))[:op])                         { [1, op] }
            / r((glyph("*") / glyph("/") / glyph("%"))[:op]) { [2, op] }
            / r((glyph("+") / glyph("-"))[:op])              { [3, op] }
            / r((mglyph("<=") / mglyph("<=>") / mglyph(">=")
                / glyph("<")  /  glyph(">"))[:op])           { [4, op] }
          )[:details]) { [:op_normal, *details] }
          
          left_op_flow: r((
              r((mglyph("&&") / mglyph("&?") / mglyph("??")
               / mglyph("||") / mglyph("&?"))[:op])          { [5, op] }
            / r((mglyph("|>"))[:op])                         { [6, op] }
          )[:details]) { [:op_flow, *details] }
          
          rule left_op: left_op_normal / left_op_flow
          
          # Achieve left-associativity through iteration.
          #
          # PEG parsers get tripped up by left recursion
          # (in contrast to LALR parsers, which prefer left recursion).
          # This is a well-understood limitation, but refer to:
          # http://www.dalnefre.com/wp/2011/05/parsing-expression-grammars-part-4/
          # for an easy-to-understand explanation of this problem and this solution.
          #
          rule left_chained_operation:
            r(s+ left_op[:to] +s+ expr_atom[:n1])
              { [to, n1] }
          
          rule left_chained_operations:
            r(expr_atom[:n0] + left_chained_operation.+[:nlist])
          {
            nlist.flatten!(1)
            nlist.unshift(n0)
            
            # Given a node,op list ([node, op, node, op, ... node]) and target priority,
            # collapse the (node, op, node) groups where the priority is the same.
            #
            # This function is meant to be called several times on the same list,
            # with a different priority each time to collapse in order of precedence.
            #
            collapse = &|input, target_priority| {
              output = []
              
              # Scan through, reducing or shifting based on the operator
              Loop.run {
                (input.count > 2) || Loop.break
                n0 = input.shift
                op = input.shift
                
                op.tap |type, priority, token| {
                  (priority == target_priority) &? (
                    n1 = input.shift
                    input.unshift([type, operator: token, left: n0, right: n1])
                  ) ?? (
                    output.push(n0)
                    output.push(op)
                  )
                }
              }
              
              # Push the last item remaining
              output.push(input.shift)
              
              input.replace(output)
            }
            
            collapse.call(nlist, 1)
            collapse.call(nlist, 2)
            collapse.call(nlist, 3)
            collapse.call(nlist, 4)
            collapse.call(nlist, 5)
            collapse.call(nlist, 6)
            
            # There should only be one resulting node left
            (nlist.count == 1)
              || raise("Failed to fully collapse left_chained_operations: "nlist"")
            
            nlist.first
          }
          
          ##
          # Invocations and Quests (soft-failing invocations)
          
          rule left_invoke_op:
            mglyph(".?")
          / glyph(".")
          
          rule left_chained_invocation:
            r(s+ left_invoke_op[:to] +s+ invoke[:n1]) { [to, n1] }
          / r(s[:to]+ elem_invoke[:n1])               { [to, n1] }
          
          rule left_chained_invocations:
            r(expr_atom_not_chained[:n0] + left_chained_invocation.+[:nlist])
          {
            n0 = n0()
            nlist.each |op, n1| {
              n0 = (op.sym == :".?") &? (
                [:quest, loc: n1.last[:loc], receiver: n0, questable: n1]
              ) ?? (
                n1.last[:receiver] = n0
                n1
              )
            }
            n0
          }
          
          opt_paren_group: (r(s+ paren_group[:n]) { n }).-
          opt_brace_group: (r(s+ brace_group[:n]) { n }).-
          opt_brack_group: (r(s+ brack_group[:n]) { n }).-
          
          invoke_name:
            local_word
          / r(left_op_normal[:ary]) { ary.last } # discard precedence info
          
          rule invoke:
            r(invoke_name[:name]
            + opt_paren_group[:arguments] + opt_brace_group[:block])
              { [:invoke, loc: name, receiver: null, name: name.sym,
                  arguments: arguments, block: block] }
          
          rule elem_invoke:
            r(brack_group[:arguments] + opt_brace_group[:block])
              { [:invoke, loc: arguments.start, receiver: null, name: :"[]",
                  arguments: arguments, block: block] }
        }
      }
      
      [helpers]
      
      const escape_encodings: {
        hash = ::Ruby::Hash.new
        hash["\\a"] =  7.chr # \a  0x07  Bell or alert
        hash["\\b"] =  8.chr # \b  0x08  Backspace
        # TODO:              # \cx       Control-x
        # TODO:              # \C-x      Control-x
        hash["\\e"] = 27.chr # \e  0x1b  Escape
        hash["\\f"] = 12.chr # \f  0x0c  Formfeed
        # TODO:              # \M-\C-x   Meta-Control-x
        hash["\\n"] = 10.chr # \n  0x0a  Newline
        # TODO:              # \nnn      Octal notation, where n is a digit
        hash["\\r"] = 13.chr # \r  0x0d  Carriage return
        hash["\\s"] = 32.chr # \s  0x20  Space
        hash["\\t"] =  9.chr # \t  0x09  Tab
        hash["\\v"] = 11.chr # \v  0x0b  Vertical tab
        # TODO:              # \xnn      Hexadecimal notation, where n is a digit
        hash
      }
      
      # Encode escape characters in string literals
      # TODO: rigorously test and refine
      encode_escapes: |str| {
        str.gsub(Regexp.new("\\\\.")) |substr| {
          escape_encodings.fetch(substr, substr[-1])
        }
      }
      
      [handlers]
      
      none: {}
      
      integer: |integer:|
        ast.numeric(integer, integer.integer)
      
      symbol: |loc:, content:|
        ast.symbol(loc, helpers.encode_escapes(content.text).to_sym)
      
      string: |loc:, content:|
        ast.str(loc, helpers.encode_escapes(content.text))
      
      constant: |loc:, top:, words:|
        ast.const(words.first, top, words.map(&:sym))
      
      sequence: |group:|
        Parsers::Sequence.parse(group)
      
      op_normal: |left:, operator:, right:| {
        left  = send(*left)
        right = send(*right)
        ast.invoke(operator, left, operator.sym, ast.args(right, [right]))
      }
      
      op_flow: |left:, operator:, right:| {
        op_sym = operator.sym
        left   = send(*left)
        right  = send(*right)
        (op_sym == :"|>") &? (
          ast.pipe_op(left, left, right)
        ) ?? (
          ast.branch_op(operator, op_sym, left, right)
        )
      }
      
      invoke: |loc:, receiver:, name:, arguments:, block:| {
        receiver  = receiver  && send(*receiver)
        block     = block     && Parsers::Sequence.parse(block)
        arguments = arguments && (
          arg_array = Parsers::Sequence.parse(arguments).array
          ast.args(arg_array.first || loc, arg_array)
        )
        ast.invoke(loc, receiver, name, arguments, block)
      }
      
      quest: |loc:, receiver:, questable:|
        ast.quest(loc, send(*receiver), send(*questable))
    }
    
  }
}
