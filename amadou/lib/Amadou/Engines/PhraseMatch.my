
Amadou << {
  Engines << {
    
    PhraseMatch < BasicObject {
      Checklist < BasicObject {
        var list: []
        "+": |next| {
          list.concat(next.list)
          self
        }
        size: list.size
        size_varies?: list.any?(&:size_varies?)
        
        normalize!: {
          expect_space = true
          new_list = []
          
          list.each |item| {
            if(expect_space && item.is_a?(CheckTerm)) {
              new_list.push(CheckSpace.new(implicit: true))
              expect_space = !expect_space
            }
            new_list.push(item)
            expect_space = !expect_space
          }
          if(expect_space) {
            new_list.push(CheckSpace.new(implicit: true))
          }
          
          self.list = new_list
          self
        }
        
        check: |phrase| {
          checked_items = []
          
          fails = list.each_with_index.detect |item, idx| {
            item.implicit? &? false ?? (
              phrase_item = item.size_varies?
                &? Nodes::Phrase.from(phrase.list[Ruby::Range.new(idx, -1)])
                ?? phrase.list[idx]
              
              checked_items.push(phrase_item)
              item.fails_check?(phrase_item)
            )
          }
          fails &? null ?? checked_items
        }
      }
      
      CheckTokenized < BasicObject {
        var truths: []
        var text: null
        
        static from: |*args, implicit:false| {
          obj = new
          args.each |arg| {
            arg.is_a?(Symbol) && obj.truths.push(arg)
            arg.is_a?(String) && (obj.text = arg)
          }
          obj.implicit = implicit
          obj
        }
        
        var implicit: false
        implicit?: implicit
        const size_varies?: false
        
        fails_check?: |term| {
            (truths.detect |method| { !(term.__send__(method)) })
          || (text && !(text == term.text))
        }
      }
      
      CheckSpace < CheckTokenized {
        var truths: [:is_space?]
      }
      
      CheckTerm < CheckTokenized {
        var truths: [:is_term?]
      }
      
      CheckSubphrase < BasicObject {
        static from: new
        
        const implicit?: false
        const size_varies?: true
        
        fails_check?: |subphrase| false
      }
      
      checklist: |*list| Checklist.new(list: list)
      
      space: |*a| checklist(CheckSpace.from(*a, implicit: true))
      word:  |*a| checklist(CheckTerm.from(:is_word?, *a))
      glyph: |*a| checklist(CheckTerm.from(:is_glyph?, *a))
      subphrase: |*a| checklist(CheckSubphrase.new)
      
      match: |phrase| {
        args = null
        name = rules.memes.keys.detect |name| {
          rule = rules.__send__(name)
          psize = phrase.list.size
          
          (rule.size_varies? &? (rule.size < psize) ?? (rule.size == psize))
          && (args = rule.check(phrase))
        }
        args &? [name, args] ?? null
      }
      
      [rules]
      # Empty - user rules go here
      
      [decorators]
      const rule: Decorator {
        apply: |meme| {
          rule = meme.result || Checklist.new
          rule.normalize!
          meme.body = Rubinius::Thunk.new(rule)
        }
      }
    }
    
  }
}
